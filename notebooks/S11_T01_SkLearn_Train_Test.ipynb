{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# [IT Academy - Data Science with Python](https://www.barcelonactiva.cat/es/itacademy)\n",
    "## S11 T01: SkLearn Train Test  \n",
    "### [Github SkLearn Train Test](https://github.com/jesussantana/SkLearn-Train-Test)\n",
    "\n",
    "[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)  \n",
    "[![Made withJupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange?style=for-the-badge&logo=Jupyter)](https://jupyter.org/try)  \n",
    "[![wakatime](https://wakatime.com/badge/github/jesussantana/SkLearn-Train-Test.svg)](https://wakatime.com/badge/github/jesussantana/SkLearn-Train-Test)  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data treatment\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "import missingno as msno\n",
    "\n",
    "# # Graphics\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Preprocessing and modeling\n",
    "# ==============================================================================\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_1samp,ttest_ind\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats.mstats import gmean,hmean\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "# Various\n",
    "# ==============================================================================\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "from itertools import product\n",
    "from fitter import Fitter, get_common_distributions\n",
    "\n",
    "# Pandas configuration\n",
    "# ==============================================================================\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Matplotlib configuration\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn configuration\n",
    "# ==============================================================================\n",
    "sns.set_theme(style='darkgrid', palette='deep')\n",
    "dims = (20, 16)\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scripts folder configuration\n",
    "# ==============================================================================\n",
    "import sys\n",
    "new_path = '../scripts/'\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)"
   ]
  },
  {
   "source": [
    "### Exercise 1: \n",
    "  - Split the DelayedFlights.csv dataset into train and test. Study the two sets separately, at a descriptive level."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 2: \n",
    "  - Apply some transformation process (standardize numerical data, create dummy columns, polynomials."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 3: \n",
    "  - Summarize the new columns generated statistically and graphically"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "Exercise 1, 2 & 3 developed below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path folder configuration\n",
    "# ===============================================================================\n",
    "\n",
    "path = '../data/'\n",
    "file = 'raw/DelayedFlights.csv'\n",
    "\n",
    "df_raw = pd.read_csv(path+file)"
   ]
  },
  {
   "source": [
    "## Exploratory analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Exploration Script\n",
    "# ===============================================================================\n",
    "\n",
    "import exploration\n",
    "\n",
    "exploration.summary(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.drop(labels='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "source": [
    "- Data sampling to reduce loading time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.001, random_state = 6858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "new_path = '../scripts/'\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "### Drop features that we do not adds value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features\n",
    "df.drop(axis=1,columns=['Year', 'Cancelled', 'CancellationCode', 'TailNum','FlightNum', 'Diverted'], inplace=True)"
   ]
  },
  {
   "source": [
    "## Numerical variables correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['float64', 'int']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graph for each numerical variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns\n",
    "\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = df,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 8, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 8)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribution Numerical Variable', fontsize = 10, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Distribution_Numerical_Variable.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graph for each numerical variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns\n",
    "\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.regplot(\n",
    "        x           = df[colum],\n",
    "        y           = df['ArrDelay'],\n",
    "        color       = \"gray\",\n",
    "        marker      = '.',\n",
    "        scatter_kws = {\"alpha\":0.4},\n",
    "        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n",
    "        ax          = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"ArrDelay vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    #axes[i].ticklabel_format(style='sci', scilimits=(-4,4), axis='both')\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 8)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "    #if (i-1 >= len(columnas_numeric)-1): break\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Correlation with ArrDelay', fontsize = 10, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Distribution_Each_Numerical_Variable.png\")"
   ]
  },
  {
   "source": [
    "### We can observe a strong correlation with DepDelay"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Numerical variables correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric columns\n",
    "# ==============================================================================\n",
    "def tidy_corr_matrix(corr_mat):\n",
    "    \n",
    "    # Function to convert a pandas correlation matrix to tidy format\n",
    "    \n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n",
    "\n",
    "\n",
    "\n",
    "corr_matrix = df.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap matrix of correlations\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot     = True,\n",
    "    cbar      = False,\n",
    "    annot_kws = {\"size\": 10},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "ax.set_yticklabels(\n",
    "    ax.get_yticklabels(),\n",
    "    rotation = 0,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "ax.tick_params(labelsize = 10)\n",
    "plt.savefig(\"../reports/figures/Heatmap_Matrix_Correlations.png\")"
   ]
  },
  {
   "source": [
    "## Qualitative variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative variables (object type)\n",
    "# ============================================================================\n",
    "df.select_dtypes (include = ['object']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for each qualitative variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 40))\n",
    "axes = axes.flat\n",
    "columnas_object = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    df[colum].value_counts().plot.barh(ax = axes[i])\n",
    "    axes[i].set_title(colum, fontsize = 10, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 11)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [7, 8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Qualitative variable distribution',\n",
    "             fontsize = 11, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Each_Qualtitative_Variable.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph relationship between the ArrDelay and each qualitative variables\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 50))\n",
    "axes = axes.flat\n",
    "columnas_object = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    sns.violinplot(\n",
    "        x     = 'ArrDelay',\n",
    "        y     = colum,\n",
    "        data  = df,\n",
    "        color = \"white\",\n",
    "        ax    = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"{colum} vs ArrDelay\", fontsize = 15, fontweight = \"bold\")\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 11)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [7, 8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('ArrDelay distribution by group', fontsize = 30, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/ArrDelay_vs_Qualitative_Variable.png\")"
   ]
  },
  {
   "source": [
    "## Create Categorical Dummies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script created for transform categorical to dummies\n",
    "# ===============================================================================\n",
    "\n",
    "import categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = categorical.transform_dummies(df, \"UniqueCarrier\")"
   ]
  },
  {
   "source": [
    "## Create Ordinal Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding \n",
    "\n",
    "geo_encoding = OrdinalEncoder()\n",
    "\n",
    "geo=['Origin','Dest']\n",
    "\n",
    "df[geo] = geo_encoding.fit_transform(df[geo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "## Imputation of missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "msno.bar(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script created for transform missing data\n",
    "# ===============================================================================\n",
    "\n",
    "import missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:] = missing.transform(df[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path + \"processed/DelayedFlightsProcessed.csv\", index = False, header = True)"
   ]
  },
  {
   "source": [
    "*****************************************************************************\n",
    "*****************************************************************************\n",
    "*****************************************************************************\n",
    "*****************************************************************************"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Divide the data set into training set and test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'processed/DelayedFlightsProcessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Matrix\n",
    "X = df.drop('ArrDelay', axis = 'columns')\n",
    "# Vector\n",
    "y = df['ArrDelay']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call train_test_split on the data and capture the results\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state = 6858)"
   ]
  },
  {
   "source": [
    "## Checking if the training set was correcly splitted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set - Features: \", X_train.shape)\n",
    "print(\"Test set - Features: \", X_test.shape)"
   ]
  },
  {
   "source": [
    "## Checking  Train, Test partition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>>Train partition\")\n",
    "print(\"-----------------------\")\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test partition\")\n",
    "print(\"-----------------------\")\n",
    "print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_train[['ArrDelay', 'DepDelay', 'Distance', 'ArrTime']])\n",
    "plt.savefig(\"../reports/figures/train_pairplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_test[['ArrDelay', 'DepDelay', 'Distance', 'ArrTime']])\n",
    "plt.savefig(\"../reports/figures/test_pairplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(path + \"interim/X_train.csv\", index = False, header = True)\n",
    "X_test.to_csv(path + \"interim/X_test.csv\", index = False, header = True)"
   ]
  },
  {
   "source": [
    "## Scale Train and Test Data With Standard Scaler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Import script create for Standar Scaling\n",
    "# ===============================================================================\n",
    "\n",
    "import scaling\n",
    "\n",
    "X_train, X_test = scaling.transform(X_train, X_test, X_train.columns)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_train[['ArrDelay', 'DepDelay', 'Distance', 'ArrTime']])\n",
    "plt.savefig(\"../reports/figures/X_train_stand_pairplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_test[['ArrDelay', 'DepDelay', 'Distance', 'ArrTime']])\n",
    "plt.savefig(\"../reports/figures/X_test_stand_pairplot.png\")"
   ]
  },
  {
   "source": [
    "## Distribution Numerical Variable X train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.select_dtypes(include=['float64', 'int']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graph for each numerical variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(30, 15))\n",
    "axes = axes.flat\n",
    "columnas_numeric = X_train.select_dtypes(include=['float64', 'int']).columns\n",
    "\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = X_train,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 8, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 8)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribution Numerical Variable', fontsize = 10, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Distribution_Numerical_Variable_Xtrain.png\")"
   ]
  },
  {
   "source": [
    "## Numerical variables correlation X train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric columns\n",
    "# ==============================================================================\n",
    "def tidy_corr_matrix(corr_mat):\n",
    "    \n",
    "    # Function to convert a pandas correlation matrix to tidy format\n",
    "    \n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n",
    "\n",
    "\n",
    "\n",
    "corr_matrix = X_train.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap matrix of correlations\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot     = True,\n",
    "    cbar      = False,\n",
    "    annot_kws = {\"size\": 10},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "ax.set_yticklabels(\n",
    "    ax.get_yticklabels(),\n",
    "    rotation = 0,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "ax.tick_params(labelsize = 10)\n",
    "plt.savefig(\"../reports/figures/Heatmap_Matrix_Correlations_Xtrain.png\")"
   ]
  },
  {
   "source": [
    "## Qualitative variables Xtrain"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for each qualitative variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 40))\n",
    "axes = axes.flat\n",
    "columnas_object = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    df[colum].value_counts().plot.barh(ax = axes[i])\n",
    "    axes[i].set_title(colum, fontsize = 10, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 11)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [7, 8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Qualitative variable distribution',\n",
    "             fontsize = 11, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Each_Qualtitative_Variable_Xtrain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_labels = title_type.show_id.sort_values().index \n",
    "type_counts = title_type.show_id.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20,10)) \n",
    "the_grid = GridSpec(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Spectral')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(the_grid[0, 1], aspect=1, title='Types of Netflix Titles')\n",
    "type_show_ids = plt.pie(type_counts, labels=type_labels, autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Distribution Numerical Variable X test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graph for each numerical variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_numeric = X_test.select_dtypes(include=['float64', 'int']).columns\n",
    "columnas_numeric = columnas_numeric.drop('ArrDelay')\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = df,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 8, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 8)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribution Numerical Variable', fontsize = 10, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Distribution_Numerical_Variable_Xtest.png\")"
   ]
  },
  {
   "source": [
    "## Numerical variables correlation X test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric columns\n",
    "# ==============================================================================\n",
    "def tidy_corr_matrix(corr_mat):\n",
    "    \n",
    "    # Function to convert a pandas correlation matrix to tidy format\n",
    "    \n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n",
    "\n",
    "\n",
    "\n",
    "corr_matrix = X_test.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap matrix of correlations\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot     = True,\n",
    "    cbar      = False,\n",
    "    annot_kws = {\"size\": 10},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "ax.set_yticklabels(\n",
    "    ax.get_yticklabels(),\n",
    "    rotation = 0,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "ax.tick_params(labelsize = 10)\n",
    "plt.savefig(\"../reports/figures/Heatmap_Matrix_Correlations_Xtest.png\")"
   ]
  },
  {
   "source": [
    "## Qualitative variables X test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for each qualitative variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 40))\n",
    "axes = axes.flat\n",
    "columnas_object = .select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    x_test[colum].value_counts().plot.barh(ax = axes[i])\n",
    "    axes[i].set_title(colum, fontsize = 10, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 11)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [7, 8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Qualitative variable distribution',\n",
    "             fontsize = 11, fontweight = \"bold\")\n",
    "plt.savefig(\"../reports/figures/Each_Qualtitative_Variable_Xtest.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(path + \"interim/X_train_stand.csv\", index = False, header = True)\n",
    "X_test.to_csv(path + \"interim/X_test_stand.csv\", index = False, header = True)"
   ]
  }
 ]
}